{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c40aba",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d1bb802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\18573\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import json\n",
    "from os import listdir\n",
    "import glob\n",
    "from scipy import spatial\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bed66b",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30bb759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = pd.read_csv('./dataset/survey_results_public.csv')\n",
    "jobs = pd.read_csv('./dataset/dice_com-job_us_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49bee4e",
   "metadata": {},
   "source": [
    "## Building dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2fb0860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for platforms\n",
    "platforms_unclean=survey.loc[:,\"PlatformWorkedWith\"].tolist()\n",
    "platforms_unclean_next=survey.loc[:,\"PlatformDesireNextYear\"].tolist()\n",
    "platforms=[]\n",
    "for string1,string2 in list(zip(platforms_unclean,platforms_unclean_next)):\n",
    "    if(not pd.isnull(string1)):\n",
    "        ele=string1.split(\";\")\n",
    "        for plat in ele:\n",
    "            if(plat not in platforms):\n",
    "                platforms.append(plat)\n",
    "    if(not pd.isnull(string2)):\n",
    "        ele=string2.split(\";\")\n",
    "        for plat in ele:\n",
    "            if(plat not in platforms):\n",
    "                platforms.append(plat)\n",
    "platform_df=pd.DataFrame.from_dict({'Platform':platforms})\n",
    "platform_df.to_csv(\"./dataset/platforms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e0d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for frameworks\n",
    "frameworks_unclean=survey.loc[:,\"FrameworkWorkedWith\"].tolist()\n",
    "frameworks_unclean_next=survey.loc[:,\"FrameworkDesireNextYear\"].tolist()\n",
    "frameworks=[]\n",
    "for string1,string2 in list(zip(frameworks_unclean,frameworks_unclean_next)):\n",
    "    if(not pd.isnull(string1)):\n",
    "        ele=string1.split(\";\")\n",
    "        for plat in ele:\n",
    "            if(plat not in frameworks):\n",
    "                frameworks.append(plat)\n",
    "    if(not pd.isnull(string2)):\n",
    "        ele=string2.split(\";\")\n",
    "        for plat in ele:\n",
    "            if(plat not in frameworks):\n",
    "                frameworks.append(plat)\n",
    "framework_df=pd.DataFrame.from_dict({'frameworks':frameworks})\n",
    "framework_df.to_csv(\"./dataset/frameworks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f19f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for Languages\n",
    "languages_unclean=survey.loc[:,\"LanguageWorkedWith\"].tolist()\n",
    "languages_unclean_next=survey.loc[:,\"LanguageDesireNextYear\"].tolist()\n",
    "languages=[]\n",
    "for string1,string2 in list(zip(languages_unclean,languages_unclean_next)):\n",
    "    if(not pd.isnull(string1)):\n",
    "        ele=string1.split(\";\")\n",
    "        for plat in ele:\n",
    "            if(plat not in languages):\n",
    "                languages.append(plat)\n",
    "    if(not pd.isnull(string2)):\n",
    "        ele=string2.split(\";\")\n",
    "        for plat in ele:\n",
    "            if(plat not in languages):\n",
    "                languages.append(plat)\n",
    "languages_df=pd.DataFrame.from_dict({'languages':languages})\n",
    "languages_df.to_csv(\"./dataset/languages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d71b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for databases\n",
    "databases_unclean=survey.loc[:,\"DatabaseWorkedWith\"].tolist()\n",
    "databases_unclean_next=survey.loc[:,\"DatabaseDesireNextYear\"].tolist()\n",
    "databases=[]\n",
    "for string1,string2 in list(zip(databases_unclean,databases_unclean_next)):\n",
    "    if(not pd.isnull(string1)):\n",
    "        ele=string1.split(\";\")\n",
    "        for plat in ele:\n",
    "            if(plat not in databases):\n",
    "                databases.append(plat)\n",
    "    if(not pd.isnull(string2)):\n",
    "        ele=string2.split(\";\")\n",
    "        for plat in ele:\n",
    "            if(plat not in databases):\n",
    "                databases.append(plat)\n",
    "databases_df=pd.DataFrame.from_dict({'databases':databases})\n",
    "databases_df.to_csv(\"./dataset/databases.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c8ecc1",
   "metadata": {},
   "source": [
    "## Job profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(arr1,arr2):\n",
    "    ans=1- spatial.distance.cosine(arr1,arr2)\n",
    "    if(np.isnan(ans)):\n",
    "        return 0\n",
    "    else:\n",
    "        return ans\n",
    "class job_postings:    \n",
    "    def __init__(self,link):\n",
    "        self.df2=pd.read_csv(link)\n",
    "        self.training_range=int(len(self.df2.loc[:,'uniq_id']))\n",
    "    def check_threshold(self,title,threshold,ele):\n",
    "        if(ele[0]!=title and abs(ele[1]-threshold)<0.03):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def categorize_jobs(self):\n",
    "        # #Predefined categories\n",
    "        #Compare similarities of word embeddings\n",
    "        nlp=spacy.load('en_core_web_lg')\n",
    "        job_id=self.df2.loc[:,'uniq_id'].tolist()[:self.training_range]\n",
    "        job_titles=self.df2.loc[:,'jobtitle'].tolist()[:self.training_range]\n",
    "        job_descriptions=self.df2.loc[:,'jobdescription'].tolist()[:self.training_range]\n",
    "        final_cat=pd.DataFrame(index=job_id)\n",
    "        #categories=['Network Engineer','Application Development','Big Data','Data Analyst','Software Developer','DevOps','Software Testing','Front End','Back End','Full Stack','Web Development','Information Security','Mobile developer','System Administrator','Business Analyst','Manager','Cloud']\n",
    "        categories=['Network Engineer','Full stack','QA/Test Developer','Enterprise application','DevOps','Mobile Developer','Back End','Database Administrator(DBA)','Front End','Game developer','System Administrator','Data Scientist','Business analyst','Sales professional','Product Manager','Information Security','Software Developer/Java Developer','Web Developer','Cloud Computing']\n",
    "        for category in categories:\n",
    "            final_cat[category]=np.nan\n",
    "        for job_t_d in list(zip(job_id,job_titles,job_descriptions)):\n",
    "            id_job=job_t_d[0]\n",
    "            job_i=job_t_d[1]\n",
    "            job_d=job_t_d[2]\n",
    "            job_title=nlp(job_i.lower())\n",
    "            job_description=nlp(job_d.lower())\n",
    "            match_cat_title=dict()\n",
    "            match_cat_description=dict()\n",
    "            for category in categories:\n",
    "                word=nlp(category.lower())\n",
    "                match_cat_title[category]=job_title.similarity(word)\n",
    "                match_cat_description[category]=job_description.similarity(word)\n",
    "            match_cat_title=sorted(match_cat_title.items(),key=lambda x:x[1],reverse=True)\n",
    "            match_cat_description=sorted(match_cat_description.items(),key=lambda x:x[1],reverse=True)\n",
    "            #a represents max\n",
    "            #if(match_cat_title[0][1]>0.5 or match_cat_description[0][1]>0.5):\n",
    "            a=match_cat_title[0]\n",
    "            match_cat_description=list(filter(lambda x: self.check_threshold(a[0],a[1],x),match_cat_description))\n",
    "            if(len(match_cat_description)!=0):\n",
    "                #print(match_cat_description)\n",
    "                #print(id_job)\n",
    "                #b=match_cat_description[0]\n",
    "                final_cat.loc[id_job,a[0]]=1\n",
    "                match_cat_description.extend([(match_cat_title[0][0],1)])\n",
    "                sum_proportion=sum([x[1] for x in match_cat_description])\n",
    "                for ele in match_cat_description:\n",
    "                    final_cat.loc[id_job,ele[0]]=ele[1]/sum_proportion\n",
    "            else:\n",
    "                #print(id_job)\n",
    "                final_cat.loc[id_job,a[0]]=1\n",
    "        return final_cat\n",
    "    def clean_skills(self):\n",
    "        extracted_skills=dict()\n",
    "        job_skills=np.asarray(self.df2.loc[:,\"skills\"])\n",
    "        for i in range(self.training_range):\n",
    "            #print(i)\n",
    "            #Method 1: Manual pre-processing\n",
    "            job_id=self.df2.iloc[i,-1]\n",
    "            #Method 2:Using NLTK\n",
    "            tokenizer=nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "            #print(job_skills[i])\n",
    "            if(pd.isnull(job_skills[i])):\n",
    "                continue\n",
    "            stopwords_list=stopwords.words(\"english\")\n",
    "            tokens=re.split(\"|\".join([\",\",\" and\",\"/\",\" AND\",\" or\",\" OR\",\";\"]),job_skills[i])\n",
    "            tokens=list(set(tokens))\n",
    "            extracted_skills[job_id]=[]\n",
    "            extracted_skills[job_id].extend(tokens)\n",
    "        return extracted_skills\n",
    "    def extract_skills(self,extracted_skills):\n",
    "        df_languages=pd.read_csv('./dataset/languages.csv')\n",
    "        df_frameworks=pd.read_csv(\"./dataset/frameworks.csv\")\n",
    "        df_database=pd.read_csv(\"./dataset/databases.csv\")\n",
    "        #df_os=pd.read_csv(\"./dataset/operating_systems.csv\")\n",
    "        df_plat=pd.read_csv(\"./dataset/platforms.csv\")\n",
    "        \n",
    "        frameworks=df_frameworks.iloc[:,1].tolist()\n",
    "        frameworks=[str(x).lower().strip() for x in frameworks]\n",
    "        #frameworks=[str(x).split(\",\")[0] for x in df_frameworks.iloc[:,1]]\n",
    "        \n",
    "        languages=list(df_languages.iloc[:,0])\n",
    "        languages=[str(x).lower().strip() for x in languages]\n",
    "        #frameworks=[x.lower().strip().split('\\t')[0] for x in frameworks]\n",
    "        \n",
    "        databases=df_database.iloc[:,0].tolist()\n",
    "        databases=[str(x).lower().strip() for x in databases]\n",
    "        #op_systems=df_os.iloc[:,0].tolist()\n",
    "        #op_systems=[x.lower().strip() for x in op_systems]\n",
    "        \n",
    "        platforms=df_plat.iloc[:,1].tolist()\n",
    "        #print(platforms)\n",
    "        platforms=[str(x).lower().strip() for x in platforms]\n",
    "        #print(frameworks)\n",
    "        new_extracted=dict()\n",
    "        \n",
    "        for ele in extracted_skills.keys():\n",
    "            final_lang=''\n",
    "            final_frame=''\n",
    "            final_others=''\n",
    "            final_database=''\n",
    "            final_plat=''\n",
    "            #final_os=''\n",
    "            #print(extracted_skills[ele])\n",
    "            \n",
    "            for skill in extracted_skills[ele]:\n",
    "                skill_base=skill.lower().strip()\n",
    "                #print(skill_base)\n",
    "                if(skill_base in languages):\n",
    "                    if(final_lang==''):\n",
    "                        final_lang=skill_base\n",
    "                    else:\n",
    "                        final_lang=final_lang+\",\"+skill_base\n",
    "                elif(skill_base in frameworks):\n",
    "                    if(final_frame==''):\n",
    "                        final_frame=skill_base\n",
    "                    else:\n",
    "                        final_frame=final_frame+\",\"+skill_base\n",
    "                elif(skill_base in databases):\n",
    "                    if(final_database==''):\n",
    "                        final_database=skill_base\n",
    "                    else:\n",
    "                        final_database=final_database+\",\"+skill_base\n",
    "                #elif(skill_base in op_systems):\n",
    "                #    if(final_os==''):\n",
    "                #        final_os=skill_base\n",
    "                #    else:\n",
    "                #        final_os=final_os+\",\"+skill_base\n",
    "                elif(skill_base in platforms):\n",
    "                    if(final_plat==''):\n",
    "                        final_plat=skill_base\n",
    "                    else:\n",
    "                        final_plat=final_plat+\",\"+skill_base\n",
    "                else:\n",
    "                    if(final_others==''):\n",
    "                        final_others=skill_base\n",
    "                    else:\n",
    "                        final_others=final_others+\",\"+skill_base\n",
    "            new_extracted[ele]=[final_lang,final_frame,final_database,final_plat,final_others] #,final_os\n",
    "        #print((list(new_extracted.items()))[:100])\n",
    "        nlp=spacy.load('en_core_web_lg')\n",
    "        for ele,describe in list(zip(self.df2.loc[:,'uniq_id'],self.df2.loc[:,'jobdescription'].tolist()))[:self.training_range]:\n",
    "            doc=nlp(describe)\n",
    "            final_lang=''\n",
    "            final_frame=''\n",
    "            final_others=''\n",
    "            final_database=''\n",
    "            final_plat=''\n",
    "            #final_os=''\n",
    "            for ent in doc.ents:\n",
    "                word=ent.text\n",
    "                word=word.lower().strip()\n",
    "                try:\n",
    "                    if(word in languages and word not in final_lang and word not in new_extracted[ele][0].split(\",\")):\n",
    "                        if(final_lang==''):\n",
    "                            final_lang=word\n",
    "                        else:\n",
    "                            final_lang=final_lang+\",\"+word\n",
    "                    elif(word in frameworks and word not in final_frame and word not in new_extracted[ele][1].split(\",\")):\n",
    "                        if(final_frame==''):\n",
    "                            final_frame=word\n",
    "                        else:\n",
    "                            final_frame=final_frame+\",\"+word\n",
    "                    elif(word in databases and word not in final_database and word not in new_extracted[ele][2].split(\",\")):\n",
    "                        if(final_database==''):\n",
    "                            final_database=word\n",
    "                        else:\n",
    "                            final_database=final_database+\",\"+word\n",
    "                    #elif(word in op_systems and word not in final_os and word not in new_extracted[ele][3].split(\",\")):\n",
    "                    #    if(final_os==''):\n",
    "                    #        final_os=word\n",
    "                    #    else:\n",
    "                    #        final_os=final_os+\",\"+word\n",
    "                    elif(word in platforms and word not in final_plat and word not in new_extracted[ele][3].split(\",\")):\n",
    "                        if(final_plat==''):\n",
    "                            final_plat=word\n",
    "                        else:\n",
    "                            final_plat=final_plat+\",\"+word\n",
    "                    else:\n",
    "                        if(final_others==''):\n",
    "                            final_others=word\n",
    "                        else:\n",
    "                            final_others=final_others+\",\"+word\n",
    "                except:\n",
    "                    print(\"Hello\")\n",
    "                    \n",
    "            if(final_lang!=''):\n",
    "                new_extracted[ele][0]+=\",\"+final_lang\n",
    "            if(final_frame!=''):\n",
    "                new_extracted[ele][1]+=\",\"+final_frame\n",
    "            if(final_database!=''):\n",
    "                new_extracted[ele][2]+=\",\"+final_database\n",
    "            #if(final_os!=''):\n",
    "            #    new_extracted[ele][3]+=\",\"+final_os\n",
    "            if(final_plat!=''):\n",
    "                new_extracted[ele][3]+=\",\"+final_plat\n",
    "            #if(final_others!=''):\n",
    "            #    new_extracted[ele][4]+=\",\"+final_others\n",
    "            #new_extracted[ele]=[final_lang,final_frame,final_database,final_os,final_plat,final_others]\n",
    "        #extracted_skills_df=pd.DataFrame.from_dict(new_extracted,orient='index',columns=['Language','Framework','Database','Platform']) #'OS',,'Others'\n",
    "        #print('Done!')\n",
    "        return new_extracted\n",
    "    \n",
    "    def create_job_profile(self,extracted_skills_df,domain_df):\n",
    "        job_id=extracted_skills_df.index.tolist()\n",
    "        languages_df=pd.DataFrame(index=job_id)\n",
    "        platforms_df=pd.DataFrame(index=job_id)\n",
    "        frameworks_df=pd.DataFrame(index=job_id)\n",
    "        databases_df=pd.DataFrame(index=job_id)\n",
    "        \n",
    "        for job,lang,frame,plat,datab in list(zip(job_id,extracted_skills_df.loc[:,'Language'].tolist(),extracted_skills_df.loc[:,'Framework'].tolist(),extracted_skills_df.loc[:,'Platform'].tolist(),extracted_skills_df.loc[:,'Database'].tolist())):\n",
    "            #Languages\n",
    "            l=lang.split(\",\")\n",
    "            if(lang!=np.nan or lang!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in languages_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        languages_df[ele]=np.nan\n",
    "                    languages_df.loc[job,ele]=1\n",
    "            \n",
    "            #Frameworks\n",
    "            l=frame.split(\",\")\n",
    "            if(frame!=np.nan or frame!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in frameworks_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        frameworks_df[ele]=np.nan\n",
    "                    frameworks_df.loc[job,ele]=1\n",
    "\n",
    "            #Platforms\n",
    "            l=plat.split(\",\")\n",
    "            if(plat!=np.nan or plat!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in platforms_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        platforms_df[ele]=np.nan\n",
    "                    platforms_df.loc[job,ele]=1\n",
    "            \n",
    "            #Databases\n",
    "            l=datab.split(\",\")\n",
    "            if(datab!=np.nan or datab!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in databases_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        databases_df[ele]=np.nan\n",
    "                    databases_df.loc[job,ele]=1\n",
    "        #languages_df=languages_df.reindex_axis(sorted(languages_df.columns), axis=1)\n",
    "        #frameworks_df=frameworks_df.reindex_axis(sorted(frameworks_df.columns), axis=1)\n",
    "        #platforms_df=platforms_df.reindex_axis(sorted(platforms_df.columns), axis=1)\n",
    "        #databases_df=databases_df.reindex_axis(sorted(databases_df.columns), axis=1)\n",
    "        #domain_df=domain_df.reindex_axis(sorted(domain_df.columns), axis=1)\n",
    "        \n",
    "        languages_df.index.name=frameworks_df.index.name=platforms_df.index.name=databases_df.index.name=domain_df.index.name='uniq_id'\n",
    "        languages_df.to_csv(\"./dataset/languages_job_profile.csv\")\n",
    "        frameworks_df.to_csv(\"./dataset/frameworks_job_profile.csv\")\n",
    "        platforms_df.to_csv(\"./dataset/platforms_job_profile.csv\")\n",
    "        databases_df.to_csv(\"./dataset/databases_job_profile.csv\")\n",
    "        domain_df.to_csv(\"./dataset/domain_job_profile.csv\")\n",
    "\n",
    "    def clean_common_profile(self,df_user,df_job,flag):\n",
    "        #Shift .net from languages to frameworks\n",
    "        if(flag=='Language'):\n",
    "            #print(df_job.columns.tolist())\n",
    "            #bash and bash/shell\n",
    "            count=0\n",
    "            for ele in df_user.loc[:,'bash/shell']:\n",
    "                if(ele==1.0):\n",
    "                    df_user.loc[count,'bash']=1.0##\n",
    "                count=count+1\n",
    "            df_user=df_user.drop('bash/shell',axis=1)\n",
    "            count=0\n",
    "            for ele in df_job.loc[:,'bash/shell']:\n",
    "                if(ele==1.0):\n",
    "                    df_job.ix[count,'bash']=1.0##\n",
    "                count=count+1\n",
    "            df_job=df_job.drop('bash/shell',axis=1)\n",
    "\n",
    "        if(flag=='Framework'):\n",
    "            try:\n",
    "                #print(df_user.columns.tolist())\n",
    "                count=0\n",
    "                for ele in df_user.loc[:,'nodejs']:\n",
    "                    if(ele==1.0):\n",
    "                        df_user.ix[count,'node.js']=1.0\n",
    "                    count=count+1\n",
    "                df_user=df_user.drop('nodejs',axis=1)\n",
    "                count=0\n",
    "                for ele in df_job.loc[:,'nodejs']:\n",
    "                    if(ele==1.0):\n",
    "                        df_job.ix[count,'node.js']=1.0\n",
    "                    count=count+1\n",
    "                df_job=df_job.drop('nodejs',axis=1)\n",
    "\n",
    "                count=0\n",
    "                for ele in df_user.loc[:,'angularjs']:\n",
    "                    if(ele==1.0):\n",
    "                        df_user.ix[count,'angular']=1.0\n",
    "                    count=count+1\n",
    "                df_user=df_user.drop('angularjs',axis=1)\n",
    "                count=0\n",
    "                for ele in df_job.loc[:,'angularjs']:\n",
    "                    if(ele==1.0):\n",
    "                        df_job.ix[count,'angular']=1.0\n",
    "                    count=count+1\n",
    "                df_job=df_job.drop('angularjs',axis=1)\n",
    "            except:\n",
    "                print('Error')\n",
    "            \n",
    "            \n",
    "        if(flag=='Platform'):\n",
    "            print(df_user.columns.tolist())\n",
    "            \n",
    "        if(flag=='Database'):\n",
    "            try:\n",
    "                print(df_user.columns.tolist())\n",
    "                count=0\n",
    "                for ele in df_user.loc[:,'microsoft sql server']:\n",
    "                    if(ele==1.0):\n",
    "                        df_user.ix[count,'sql server']=1.0\n",
    "                    count=count+1\n",
    "                df_user=df_user.drop('microsoft sql server',axis=1)\n",
    "                count=0\n",
    "                for ele in df_job.loc[:,'microsoft sql server']:\n",
    "                    if(ele==1.0):\n",
    "                        df_job.ix[count,'sql server']=1.0\n",
    "                    count=count+1\n",
    "                df_job=df_job.drop('microsoft sql server',axis=1)\n",
    "            except:\n",
    "                print()\n",
    "        return df_user,df_job\n",
    "\n",
    "    #Input is two dataframes    \n",
    "    def create_common_profile(self,job_profile_path,user_profile_path,output_path,flag=0):\n",
    "        if(flag==0):\n",
    "            #Domain\n",
    "            userprofile=pd.read_csv(user_profile_path+\"DevType.csv\",index_col='Respondent')\n",
    "            jobprofile=pd.read_csv(job_profile_path+\"domain_job_profile.csv\")#,index_col=0)#Unnamed: 0')\n",
    "            print(\"Read from file\")\n",
    "            print(jobprofile.index)\n",
    "            #jobprofile=jobprofile.reset_index()\n",
    "            #userprofile=userprofile.reset_index()\n",
    "            #userprofile.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            jobprofile.drop('uniq_id', axis=1, inplace=True)\n",
    "            jobprofile.index.name='uniq_id'\n",
    "            #print(\"index 2in domain\")\n",
    "            #print(jobprofile.index)\n",
    "            #print(jobprofile.loc[:,'uniq_id'])\n",
    "            userprofile.rename(columns={'Product manager':'Product Manager','Back-end developer':'Back End','C-suite executive (CEO, CTO, etc.)':'C-suite executive','Data scientist or machine learning specialist':'Data Scientist','Database administrator':'Database Administrator(DBA)','Mobile developer':'Mobile Developer','Desktop or enterprise applications developer':'Enterprise application','DevOps specialist':'DevOps','Front-end developer':'Front End','Full-stack developer':'Full stack','Marketing or sales professional':'Sales professional','QA or test developer':'QA/Test Developer','System administrator':'System Administrator','Game or graphics developer':'Game developer'},inplace=True)\n",
    "            jobprofile.rename(columns={'Business analyst':'Data or business analyst'},inplace=True)\n",
    "            #print(userprofile.columns)\n",
    "            #print(jobprofile.columns)\n",
    "            #print(\"index in domain\")\n",
    "            #print(jobprofile.index)\n",
    "            #Present in userprofile but not in jobprofile\n",
    "            a=list(set(userprofile.columns)-set(jobprofile.columns))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    jobprofile[i]=0\n",
    "            b=list(set(jobprofile.columns)-set(userprofile.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    userprofile[i]=0\n",
    "            #userprofile=userprofile.set_index('Respondent')\n",
    "            #jobprofile=jobprofile.set_index('uniq_id')\n",
    "            userprofile=userprofile[sorted(userprofile.columns.tolist())]\n",
    "            jobprofile=jobprofile[sorted(jobprofile.columns.tolist())]\n",
    "            #Exclude \n",
    "\n",
    "            print(userprofile.columns==jobprofile.columns)\n",
    "\n",
    "            print(userprofile.columns)\n",
    "            print(jobprofile.columns)\n",
    "            userprofile=userprofile[userprofile.columns.tolist()]\n",
    "            jobprofile=jobprofile[jobprofile.columns.tolist()]\n",
    "            userprofile.to_csv(output_path+\"domain_user_profile.csv\")\n",
    "            jobprofile.to_csv(output_path+\"domain_job_profile.csv\")\n",
    "\n",
    "            #Languages\n",
    "            df_user=pd.read_csv(user_profile_path+\"LanguageWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(job_profile_path+\"languages_job_profile.csv\",index_col=0)\n",
    "            df_job.index.name='uniq_id'\n",
    "            print(\"index is\")\n",
    "            print(df_job.index)\n",
    "            print(df_user.columns)\n",
    "            print(df_job.columns)\n",
    "            #df_user.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            df_job.rename(columns={'visual basic .net':'vb.net'},inplace=True)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "            columns_to_add=[]\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0        \n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            print(df_job.index)        \n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "            #df_user=userprofile.reindex_axis(sorted(df_user.columns), axis=1)\n",
    "            #df_job=jobprofile.reindex_axis(sorted(df_job.columns), axis=1)\n",
    "            print(\"index 2\")\n",
    "            print(df_job.index)\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Language')\n",
    "            print(\"language is\")\n",
    "            print(df_job.index[0])\n",
    "            print(df_job.loc[df_job.index[0],:])\n",
    "            df_user.to_csv(output_path+\"languages_profile_user.csv\")\n",
    "            df_job.to_csv(output_path+\"languages_profile_job.csv\")\n",
    "\n",
    "            #Frameworks\n",
    "            df_user=pd.read_csv(user_profile_path+\"FrameworkWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(job_profile_path+\"frameworks_job_profile.csv\",index_col=0) \n",
    "            df_job.index.name='uniq_id'\n",
    "            print(df_user.columns)\n",
    "            print(df_job.columns)\n",
    "            #df_user.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.rename(columns={'visual basic .net':'vb.net'},inplace=True)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0        \n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            #userprofile=userprofile.reindex_axis(sorted(userprofile.columns), axis=1)\n",
    "            #jobprofile=jobprofile.reindex_axis(sorted(jobprofile.columns), axis=1)\n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Framework')   \n",
    "            df_user.to_csv(output_path+\"frameworks_profile_user.csv\")\n",
    "            df_job.to_csv(output_path+\"frameworks_profile_job.csv\")\n",
    "\n",
    "            #Platforms\n",
    "            df_user=pd.read_csv(user_profile_path+\"PlatformWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(job_profile_path+\"platforms_job_profile.csv\",index_col=0) \n",
    "            print(df_user.columns)\n",
    "            df_job.index.name='uniq_id'\n",
    "            print(df_job.columns)\n",
    "            #df_user.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.rename(columns={'visual basic .net':'vb.net'},inplace=True)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0\n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Platform')        \n",
    "            df_user.to_csv(output_path+\"platforms_profile_user.csv\")\n",
    "            df_job.to_csv(output_path+\"platforms_profile_job.csv\")\n",
    "\n",
    "            #Databases\n",
    "            df_user=pd.read_csv(user_profile_path+\"DatabaseWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(job_profile_path+\"databases_job_profile.csv\",index_col=0) \n",
    "            df_job.index.name='uniq_id'\n",
    "            print(df_user.columns)\n",
    "            print(df_job.columns)\n",
    "            #df_user.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            #df_job.rename(columns={'visual basic .net':'vb.net'},inplace=True)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0\n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Database')        \n",
    "            df_user.to_csv(output_path+\"databases_profile_user.csv\")\n",
    "            df_job.to_csv(output_path+\"databases_profile_job.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85254a45",
   "metadata": {},
   "source": [
    "## Create intermediate csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "594430bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=job_postings(\"./dataset/dice_com-job_us_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be931a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cat=obj.categorize_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15676580",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cat.to_csv(\"./dataset/preprocessed_df.csv\")\n",
    "extracted_skills=obj.clean_skills()\n",
    "extracted_skills_df=obj.extract_skills(extracted_skills)\n",
    "#print(extracted_skills_df)\n",
    "domain_df=pd.read_csv(\"./dataset/preprocessed_df.csv\")\n",
    "obj.create_job_profile(extracted_skills_df,domain_df)\n",
    "obj.create_common_profile(\"./dataset/\",\"./dataset/\",\"./dataset/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
